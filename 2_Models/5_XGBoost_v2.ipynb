{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a987822-0e7a-4323-b1f4-a75a87bf2bc6",
   "metadata": {},
   "source": [
    "# 1. Import Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b841756e-236e-45b1-9d2b-71fa91369bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a182c07c-c28a-432b-9b3e-96109441ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets to\n",
    "\n",
    "folder_path = '/home/maria/Desktop/Deception_project/00_Datasets_to_run/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ee6dc-c741-474c-8595-c8c381324c6c",
   "metadata": {},
   "source": [
    "# 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a23f454-ede3-4093-916b-0d2240a433b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: dolos_aggr_mean_v2.pkl\n",
      "AUC: 0.5865\n",
      "Accuracy: 58.96%\n",
      "Confusion Matrix:\n",
      "[[157  73]\n",
      " [108 103]]\n",
      "\n",
      "Dataset: dolos_aggr_max_v2.pkl\n",
      "AUC: 0.5034\n",
      "Accuracy: 51.70%\n",
      "Confusion Matrix:\n",
      "[[146  84]\n",
      " [129  82]]\n",
      "\n",
      "Dataset: dolos_aggr_std_v2.pkl\n",
      "AUC: 0.6105\n",
      "Accuracy: 57.14%\n",
      "Confusion Matrix:\n",
      "[[161  69]\n",
      " [120  91]]\n",
      "\n",
      "Dataset: dolos_aggr_temporal_v2.pkl\n",
      "AUC: 0.5466\n",
      "Accuracy: 53.74%\n",
      "Confusion Matrix:\n",
      "[[153  77]\n",
      " [127  84]]\n"
     ]
    }
   ],
   "source": [
    "classifier = XGBClassifier(\n",
    "    n_estimators = 300,         # number of trees\n",
    "    max_depth = 4,            \n",
    "    learning_rate = 0.05,      # shrinkage\n",
    "    subsample = 0.8,           # bootstrap ratio\n",
    "    colsample_bytree = 0.8,   \n",
    "    objective = 'binary:logistic',\n",
    "    eval_metric = 'logloss',\n",
    "    random_state = 0,\n",
    "    n_jobs = -1             \n",
    ")\n",
    "\n",
    "# dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# loop through all different dataset files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pkl'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_pickle(file_path)\n",
    "        \n",
    "        X = df.drop(columns=['label', 'face_id', 'video_id']).astype('float32')\n",
    "        X = X.select_dtypes(include=['number']).to_numpy().astype('float32') ## because it threw errors on dtype\n",
    "        y = df['label'].map({'lie': 0, 'truth': 1}).values\n",
    "\n",
    "        # splitting the dataset into the training set and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size = 0.3, random_state = 42\n",
    "        )\n",
    "        \n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # predict probabilities and classes\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        p = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        auc = roc_auc_score(y_test, p)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # store results\n",
    "        results[filename] = {\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Confusion Matrix\": cm\n",
    "        }\n",
    "\n",
    "# print results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\nDataset: {name}\")\n",
    "    print(f\"AUC: {metrics['AUC']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']*100:.2f}%\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics['Confusion Matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08de0e9-d83b-4bbe-bb2e-abf193c2d6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
